{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368dccec-1d58-4167-a50d-01c56d98c24e",
   "metadata": {},
   "source": [
    "<img src=\"../images/coefficient-pyconde.png\" width=1200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db52fb18-e4c3-4d38-86d6-cf10abeca5e8",
   "metadata": {},
   "source": [
    "# Whispered Secrets: Building An Open-Source Tool To Live Transcribe & Summarize Conversations\n",
    "## 1. Ollama\n",
    "**Questions?** contact@coefficient.ai / [@CoefficientData](https://twitter.com/CoefficientData)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9dfd7f-dcc6-418c-bc6b-02c7771e07fa",
   "metadata": {},
   "source": [
    "## 0. Imports üì¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2dafcdd-5794-478c-88ac-d8493aadcd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99f5e0-fea0-40bf-a43e-43701293f0f0",
   "metadata": {},
   "source": [
    "## 1. Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918b349-5966-4835-8e97-461c1fb4c70b",
   "metadata": {},
   "source": [
    "<img src=\"../images/ollama.png\" width=1200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e65c6-1acd-431c-83fc-bbd6f75c1745",
   "metadata": {},
   "source": [
    "```sh\n",
    "ollama pull llama3\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2c3c80-a488-47ac-aa2c-a32a25a0dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93ab2df-409f-437b-adb6-2da68fb8647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there! As a digital AI assistant, I don't have personal experiences or emotions, but I'm here to help you with any questions or topics you'd like to discuss. How can I assist you today? Do you have something specific in mind, or would you like me to suggest some fun and interesting things we could chat about?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hey Ollama, what's going on today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30c9b6e-c730-4abd-ad3f-3b7b0a09af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk\n",
      "pydata-generative-ai\n",
      "\n",
      "\n",
      "Whispered Secrets: Building An Open-Source Tool To Live Transcribe & Summarize Conversations\n",
      "\n",
      "John Sandall\n",
      "\n",
      "\n",
      "üïµÔ∏è Calling all Spythonistas: Do you need a live speech transcription and summarization \"secret agent\" that works offline by running on your own hardware? Learn about the latest trends in open-source GenAI tools and how to build your own in this light-hearted talk.\n",
      "\n",
      "Read more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://2024.pycon.de/program/categories/talk/\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "pycon_talks = soup.get_text()\n",
    "\n",
    "my_talk = pycon_talks.find(\"Sandall\")\n",
    "print(pycon_talks[my_talk - 127 : my_talk + 290])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6f6843-4952-45e6-99cb-d0ff1ac70dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the top 5 talk recommendations based on the abstracts:\n",
       "\n",
       "### 1. **The pragmatic Pythonic data engineer**\n",
       "Learn to make practical decisions in data engineering with Python's vast ecosystem. Avoid blindly following market guidelines and consider the reality of your situation for better performance and architecture.\n",
       "\n",
       "### 2. **Unlock the Power of Dev Containers: Build a Consistent Python Development Environment in Seconds!**\n",
       "Say goodbye to the hassle and build a Consistent Python Development Environment in Seconds!\n",
       "\n",
       "### 3. **Unleashing Confidence in SQL Development through Unit Testing**\n",
       "Confidently ship changes to your SQL data model by validating logic with a SQL unit testing framework.\n",
       "\n",
       "### 4. **When and how to start coding with kids**\n",
       "Have you always wondered when and how to start coding with your kid? This talk will shed light on all your questions, giving concrete advice on how to get started.\n",
       "\n",
       "### 5. **There is a Better Way to Automate and Manage Your (Fluid) Simulations**\n",
       "Exploring the integration of Python into Computer Aided Engineering (CAE) workflows: While shell scripts are ubiquitous, they face challenges in CAE, particularly in Computational Fluid Dynamics (CFD). Python + DVC provides a robust alternative to manage simulations at scale."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = llm.invoke(\n",
    "    f\"\"\"\n",
    "I'm going to give you a list of conference talks.\n",
    "Please can you review all the talk abstracts and recommend the top 5 talks I should go to?\n",
    "I don't want to know what the website is, just five talk recommendations.\n",
    "\n",
    "Here's the list:\n",
    "\n",
    "{pycon_talks}\n",
    "\n",
    "---\n",
    "\n",
    "Top five talk recomendations (formatted in Markdown) are:\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aea266-712f-4f6a-84fe-58779ab480f5",
   "metadata": {},
   "source": [
    "# 2. Live summarization demo ü§ñ\n",
    "Run the following from repo root:\n",
    "\n",
    "```sh\n",
    "ollama serve\n",
    "python -m demo.summarize --help\n",
    "python -m demo.summarize 'transcription_output.txt' \"summary.txt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e8a1d-469c-454a-aca0-56fab622dfae",
   "metadata": {},
   "source": [
    "<img src=\"../images/summarizer.png\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2542a-c138-4e98-bdf6-56d81838962f",
   "metadata": {},
   "source": [
    "What changes do we need to make to our Streamlit app?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b2486-8e0b-4a4e-869f-08a2c9ecdd51",
   "metadata": {},
   "source": [
    "### Change #1: `summarize()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e0e2a-f18b-4054-b3a7-44650ae7dd53",
   "metadata": {},
   "source": [
    "<img src=\"../images/summarize-function.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f443ab-dcfd-4316-ae0d-15dead361d3c",
   "metadata": {},
   "source": [
    "### Change #2: Streamlit container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c2ac9-0e69-4591-8085-80dcabeed948",
   "metadata": {},
   "source": [
    "<img src=\"../images/summarize-container.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcafa69-b0b5-4082-84bb-dc492497bb54",
   "metadata": {},
   "source": [
    "### Change #3: Summarize every 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59edf77-8e35-4bb4-88f9-d43829f4452b",
   "metadata": {},
   "source": [
    "<img src=\"../images/summarize-loop.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315f160-6c76-42f2-a69a-c0489fe6c54a",
   "metadata": {},
   "source": [
    "# üî®üíªüé§Ô∏è FINAL DEMO üîâü§ñüôè\n",
    "\n",
    "```sh\n",
    "ollama serve\n",
    "streamlit run demo/app.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
